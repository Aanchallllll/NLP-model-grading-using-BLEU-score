{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentences(text):\n",
    "   tokens = re.split(r'(\\W+)', text)\n",
    "   result = []\n",
    "   for token in tokens:\n",
    "     if token and token.strip():  #Filters out falsy values such as '', ' ',\n",
    "       result.append(token.lower())\n",
    "   return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(words, n):\n",
    "    ngram_list = []\n",
    "    \n",
    "    for i in range(len(words) - n + 1):  \n",
    "        ngram = tuple(words[i:i+n])\n",
    "        ngram_list.append(ngram)\n",
    "\n",
    "    return ngram_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brevity_penalty(reference, candidate):\n",
    "    ref_length = len(reference)\n",
    "    can_length = len(candidate)\n",
    "\n",
    "    # Brevity Penalty\n",
    "    if can_length > ref_length:\n",
    "        bp = 1\n",
    "    else:\n",
    "        penalty = 1 - (ref_length / can_length)\n",
    "        bp = np.exp(penalty)\n",
    "\n",
    "    return bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipped_precision(reference, candidate):\n",
    "    clipped_precision_score = []\n",
    "\n",
    "    for i in range(1, 5):\n",
    "        candidate_ngram_counter = Counter(ngrams(candidate, i))  # counts of n-grams for the candidate\n",
    "\n",
    "        reference_max_counts = Counter()\n",
    "        for ref in reference:\n",
    "            ref_ngram_counter = Counter(ngrams(ref, i))  # counts of n-grams for the reference\n",
    "            reference_max_counts.update(ref_ngram_counter)\n",
    "\n",
    "        total_ref_ngrams = sum(reference_max_counts.values())\n",
    "\n",
    "        clipped_counts = 0\n",
    "        for ngram in candidate_ngram_counter:\n",
    "            clipped_counts += min(candidate_ngram_counter[ngram], reference_max_counts.get(ngram, 0))\n",
    "\n",
    "        if total_ref_ngrams > 0:\n",
    "            precision_i = clipped_counts / total_ref_ngrams\n",
    "        else:\n",
    "            precision_i = 0.0\n",
    "\n",
    "        clipped_precision_score.append(precision_i)\n",
    "\n",
    "    weights = [0.25] * 4\n",
    "\n",
    "    s = sum(w_i * math.log(p_i) if p_i > 0 else -math.inf for w_i, p_i in zip(weights, clipped_precision_score))\n",
    "\n",
    "    bleu = brevity_penalty(reference, candidate) * math.exp(s)\n",
    "    return bleu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score for Test Case 1: 53.7\n",
      "BLEU Score for Test Case 2: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def bleu_score(reference, candidate):\n",
    "    return clipped_precision(reference, candidate)\n",
    "\n",
    "ref1 = tokenize_sentences(\"It is a guide to action that ensures that the military will forever heed Party commands\")\n",
    "ref2 = tokenize_sentences(\"It is the guiding principle which guarantees the military forces always being under the command of the Party\")\n",
    "ref3 = tokenize_sentences(\"It is the practical guide for the army always to heed the directions of the party\")\n",
    "\n",
    "# Test Case 1\n",
    "candidate1 = tokenize_sentences(\"It is a guide to action which ensures that the military always obeys the commands of the party\")\n",
    "bleu_case1 = bleu_score([ref1,ref2,ref3], candidate1) * 100\n",
    "print(\"BLEU Score for Test Case 1:\", round(bleu_case1, 1))\n",
    "\n",
    "# Test Case 2\n",
    "candidate2 = tokenize_sentences(\"It is the to action the troops forever hearing the activity guidebook that party direct\")\n",
    "bleu_case2 = bleu_score([ref1,ref2,ref3], candidate2) * 100\n",
    "print(\"BLEU Score for Test Case 2:\", round(bleu_case2, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
